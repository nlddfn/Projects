{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonobos coding challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "As a retail company, our goal is to maximize the relevance of each interaction\n",
    "a customer has with our brand. We can use data to contribute to this effort by\n",
    "generating personalized content for customers, for example in the form of\n",
    "outfit recommendations.\n",
    "\n",
    "The two attached files encode information about products & customer purchases.\n",
    "\n",
    "* item_attr.tsv       40 item vectors, 4 qualitative attributes\n",
    "* custo_item.tsv      100 customer vectors, up to 10 purchases\n",
    "\n",
    "Write a Python script that uses this data to build personalized outfit\n",
    "recommendations by following the steps below. Keep in mind potential\n",
    "optimizations to minimize time & space complexity as you design your solution.\n",
    "\n",
    "Outfits should contain one product from each category (top/bottom/accessory).\n",
    "\n",
    "* step 1: Map the data in item_attr.tsv into an item-attribute space with binary (0/1)features.\n",
    "* step 2: Map the data in custo_item.tsv into a customer-item space with binary (0/1) features.\n",
    "* step 3: Map revealed customer preferences to inferred customer preferences.\n",
    "* step 4: Create outfit recommendations for 10 customers using their inferred preferences and the following criteria:\n",
    "    * outfit 1:   biz formal, chilly\n",
    "    * outfit 2:   date night, warm\n",
    "    * outfit 3:   casual, hot\n",
    "\n",
    "Please submit your code and a brief write-up (max 2 pages) of your methodology.\n",
    "How would your solution scale if the number of items and customers both increased\n",
    "by several orders of magnitude? What is the most efficient way to store information\n",
    "about inferred customer preferences? What could you do to minimize the time\n",
    "between updates to customer preferences? How does the cold start problem\n",
    "appear in this data, and what could you do to address it? What additional\n",
    "data do you think might be useful in building this solution, if any?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting the environment and loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import csv\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Loading functions\n",
    "def construct_line(line, item_list):\n",
    "    # Substitute categoricals with 1/0\n",
    "\tnew_line = [line[0]] + ['0']*len(items)\t\n",
    "\tfor item in line[1:]:\n",
    "\t    index = item_list.index(item)\n",
    "\t    new_line[index] = '1'\n",
    "\t    \n",
    "\tnew_line = \" \".join( new_line )\n",
    "\tnew_line += \"\\n\"\n",
    "\treturn new_line\n",
    "\n",
    "def best_match(x,lst):\n",
    "    # Best match for recommendation. In case of tie, \n",
    "    # take a random draw\n",
    "    if max(x) == 0:\n",
    "        ind = random.choice(list(lst))\n",
    "    else:\n",
    "        cols = lst[x == max(x)]\n",
    "        ind = random.choice(cols)\n",
    "    return ind\n",
    "\n",
    "def binarize(path):\n",
    "    # Read the (subset of) customers purchase history from file,\n",
    "    # returns a dataframe with binary labels\n",
    "    f = open(path, 'rb')\n",
    "    custTmp  = csv.reader(f,delimiter='\\t')\n",
    "    custTmp.next() \n",
    "    \n",
    "    # The encoded output will be written here. Header comes from item attribute\n",
    "    o = open( 'bonobos_ds/tmp.data', 'wb' )\n",
    "    o.write(header)\n",
    "    \n",
    "    # Loop but first set the new customers, for which there is no purchase yet\n",
    "    new_cust=[]\n",
    "    while True:\n",
    "        # read until EOF\n",
    "        try:\n",
    "            cust = custTmp.next()  \n",
    "        except StopIteration:\n",
    "            break\n",
    "            \n",
    "    # if the customer has a purchase history, binarize otherwise save index        \n",
    "        if len(cust) > 1:\n",
    "            enc_cust = construct_line(cust, encoded_customer_header)             \n",
    "            o.write(enc_cust)\n",
    "        else:\n",
    "            new_cust.append(cust[0])\n",
    "            continue        \n",
    "    f.close()\n",
    "    o.close()\n",
    "    \n",
    "    df_enc = pd.read_csv('bonobos_ds/tmp.data', sep=' ',\n",
    "                            header=0, index_col=0)\n",
    "    return [new_cust, df_enc]\n",
    "\n",
    "def profile(df):\n",
    "    # calculates user profile dependent on the item features\n",
    "    \n",
    "    total_purchase = df.apply(sum,axis=1)\n",
    "    return df.dot(onehot_items).div(total_purchase,axis = 0)\n",
    "    \n",
    "    \n",
    "def recommender(user_profile, old_cust, new_cust, dress_code=None, temp=None):\n",
    "    # Calculates the recommendation for the outfit.\n",
    "    \n",
    "    # 0- Creates a mask for item already purchased by customers. \n",
    "    # These items are filteres out from the final recommendation\n",
    "    \n",
    "    mask = -(old_cust-1)\n",
    "    \n",
    "    # Filter products according to preferences\n",
    "    filt_items = onehot_items\n",
    "    if dress_code != None:\n",
    "       dress_code = 'dress_code_' + dress_code\n",
    "       filt_items = onehot_items.loc[onehot_items[dress_code] == 1,:]\n",
    "       \n",
    "    if temp != None:\n",
    "       temp = 'temp_' + temp\n",
    "       filt_items = filt_items.loc[filt_items[temp] == 1,:]\n",
    "       \n",
    "    #1- Recommendation for top\n",
    "    try:\n",
    "        filt_items_top = filt_items.loc[filt_items.category_top == 1,:]\n",
    "        simil_top = metrics.pairwise.cosine_similarity(user_profile, filt_items_top, dense_output=True)\n",
    "        simil_top = pd.DataFrame(data=simil_top, index=user_profile.index,\n",
    "                                 columns=filt_items_top.index).mul(mask[filt_items_top.index]) \n",
    "        recom_top = simil_top.apply(best_match,axis=1,lst=simil_top.columns)\n",
    "    except ValueError:\n",
    "        recom_top = pd.DataFrame(data=[base_recommendation[0]]*len(user_profile.index), index=user_profile.index)\n",
    "    \n",
    "    #2- Recommendation for bottom\n",
    "    try:\n",
    "        filt_items_bot = filt_items.loc[filt_items.category_bottom == 1,:]\n",
    "        simil_bot = metrics.pairwise.cosine_similarity(user_profile, filt_items_bot, dense_output=True)\n",
    "        simil_bot = pd.DataFrame(data=simil_bot, index=user_profile.index, \n",
    "                                 columns=filt_items_bot.index).mul(mask[filt_items_bot.index])\n",
    "        recom_bot = simil_bot.apply(best_match,axis=1,lst=simil_bot.columns)\n",
    "    except ValueError:\n",
    "        recom_bot = pd.DataFrame(data=[base_recommendation[1]]*len(user_profile.index), index=user_profile.index)\n",
    "    \n",
    "    #3- Recommendation for accessory\n",
    "    try:\n",
    "        filt_items_acc = filt_items.loc[filt_items.category_accessory == 1,:]\n",
    "        simil_acc = metrics.pairwise.cosine_similarity(user_profile, filt_items_acc, dense_output=True)\n",
    "        simil_acc = pd.DataFrame(data=simil_acc, index=user_profile.index, \n",
    "                                 columns=filt_items_acc.index).mul(mask[filt_items_acc.index])\n",
    "        recom_acc = simil_acc.apply(best_match,axis=1,lst=simil_acc.columns)\n",
    "    except ValueError:\n",
    "        recom_acc = pd.DataFrame(data=[base_recommendation[2]] * len(user_profile.index), index=user_profile.index)\n",
    "    \n",
    "    recommendations = pd.concat([recom_top, recom_bot,recom_acc], axis = 1)\n",
    "    recommendations.columns = ['Top', 'Bottom', 'Accessory']\n",
    "    \n",
    "    # Now let's provide a recommendation for customer with no purchase history.   \n",
    "    recommendations_newcust = pd.DataFrame([base_recommendation] * len(new_cust),\n",
    "                    columns=['Top', 'Bottom', 'Accessory'],index=new_cust )\n",
    "                    \n",
    "    return pd.concat([recommendations, recommendations_newcust], axis=0)\n",
    "\n",
    "def bonobos_recommender(path,dress_code=None,temp=None):\n",
    "    # Wrapper for the functions described above. Given a tcv \n",
    "    # file with customer purchase history and (optionally)\n",
    "    # a preference on the features, the function provides\n",
    "    # a recommended outfit. If the request produces no result\n",
    "    # the base recommendation is used\n",
    "    \n",
    "    [new_cust,old_cust] = binarize(path)\n",
    "    df_usr_profile = profile(old_cust)\n",
    "    return recommender(df_usr_profile, old_cust, new_cust, dress_code, temp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: One-hot-encoding over the item-attr dataset\n",
    "In order to scale effectively with the size of the datasets, we need to know: \n",
    "1. the number of items available;\n",
    "2. the number of unique features, \n",
    "\n",
    "then we can do label binarization on both datasets. Since we are not given the number of unique attributes, we have to load the entire table item_attr. In a real situation, such attributes are already available (attributes are defined upfront, for product classification) and the one-hot encoding can be done line by line as the new products are available. The updates to the encoded item/attribute table can be appended in real time and time complexity increases with the number of updates. Given the high sparsity of the data, a sparse notation such as libsvm reduces the size of the storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 entries of items db\n",
      "        dress_code     temp   category\n",
      "item                                  \n",
      "item_1  date night   chilly        top\n",
      "item_2  biz casual     warm  accessory\n",
      "item_3   black tie      hot  accessory\n",
      "item_4  date night  perfect  accessory\n",
      "item_5      casual     cold  accessory\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dress_code_biz casual</th>\n",
       "      <th>dress_code_biz formal</th>\n",
       "      <th>dress_code_black tie</th>\n",
       "      <th>dress_code_casual</th>\n",
       "      <th>dress_code_date night</th>\n",
       "      <th>dress_code_wedding</th>\n",
       "      <th>dress_code_weekend</th>\n",
       "      <th>temp_chilly</th>\n",
       "      <th>temp_cold</th>\n",
       "      <th>temp_hot</th>\n",
       "      <th>temp_perfect</th>\n",
       "      <th>temp_warm</th>\n",
       "      <th>category_accessory</th>\n",
       "      <th>category_bottom</th>\n",
       "      <th>category_top</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>item_1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item_2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item_3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item_4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item_5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        dress_code_biz casual  dress_code_biz formal  dress_code_black tie  \\\n",
       "item                                                                         \n",
       "item_1                      0                      0                     0   \n",
       "item_2                      1                      0                     0   \n",
       "item_3                      0                      0                     1   \n",
       "item_4                      0                      0                     0   \n",
       "item_5                      0                      0                     0   \n",
       "\n",
       "        dress_code_casual  dress_code_date night  dress_code_wedding  \\\n",
       "item                                                                   \n",
       "item_1                  0                      1                   0   \n",
       "item_2                  0                      0                   0   \n",
       "item_3                  0                      0                   0   \n",
       "item_4                  0                      1                   0   \n",
       "item_5                  1                      0                   0   \n",
       "\n",
       "        dress_code_weekend  temp_chilly  temp_cold  temp_hot  temp_perfect  \\\n",
       "item                                                                         \n",
       "item_1                   0            1          0         0             0   \n",
       "item_2                   0            0          0         0             0   \n",
       "item_3                   0            0          0         1             0   \n",
       "item_4                   0            0          0         0             1   \n",
       "item_5                   0            0          1         0             0   \n",
       "\n",
       "        temp_warm  category_accessory  category_bottom  category_top  \n",
       "item                                                                  \n",
       "item_1          0                   0                0             1  \n",
       "item_2          1                   1                0             0  \n",
       "item_3          0                   1                0             0  \n",
       "item_4          0                   1                0             0  \n",
       "item_5          0                   1                0             0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 0: Load data for items and attributes\n",
    "items = pd.read_csv('bonobos_ds/item_attr.tsv', sep='\\t', header = 0, index_col=0)\n",
    "# Step 1: Apply One-hot-encoding\n",
    "onehot_items = pd.get_dummies(items[['dress_code', 'temp', 'category']])\n",
    "# Produce the list of unique items, to binarize the customer-item table\n",
    "items_list = list(items.index)\n",
    "\n",
    "print 'First 5 entries of items db'\n",
    "print items.iloc[:5,:7]\n",
    "onehot_items.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: One-hot-encoding over the customer-item dataset\n",
    "As the number of customers is the largest dimension of the problem, customers are read line by line, to improve performance. By using the unique names for items as provided by item-attr, the categorical values of customer-item  are encoded into a binary label. The resulting dataset can be saved (appended) to the encoded customer list. As for the items, writing the output in sparse notation enormously reduces the size of the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          item_1  item_2  item_3  item_4  item_5  item_6  item_7\n",
      "customer                                                        \n",
      "cust_1         0       1       0       0       0       0       0\n",
      "cust_2         0       1       0       0       0       0       0\n",
      "cust_3         0       0       0       0       0       0       0\n",
      "cust_4         0       0       0       1       0       1       0\n",
      "cust_5         0       0       0       0       0       0       0\n",
      "cust_6         0       0       0       0       0       0       0\n",
      "cust_7         0       0       0       1       0       0       0\n",
      "cust_8         0       0       0       0       0       0       0\n",
      "cust_9         0       0       0       0       0       0       0\n",
      "cust_10        0       0       0       0       1       0       0\n"
     ]
    }
   ],
   "source": [
    "# define encoded custo-item header\n",
    "encoded_customer_header = ['customer'] + items_list\n",
    "header = \" \".join(encoded_customer_header)\n",
    "header += \"\\n\"\n",
    "\n",
    "# label binarization\n",
    "path = './bonobos_ds/custo_item.tsv'\n",
    "[new_cust,old_cust] = binarize(path)\n",
    "\n",
    "print old_cust.iloc[:10,:7]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Create user profile and first prediction\n",
    "For this problem we are given binay preferences for items purchased by a customer and binary attributes related to each item. This suggests using a content based recommender system to infer for the customer preferences. The algorithm only relies on the item features, therefore it does not require to compare a user among peers. This makes it easier to interpret, it allows new/unpopular products to be recommended and it fits better the customer \"unique\" taste. \n",
    "Conversely, the model does not capture the interation between features or groups of users; for example, a new user having an empty profile cannot be initialized without using information from the peers, such as the best_seller item for each category. \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['item_7', 'item_20', 'item_38']\n"
     ]
    }
   ],
   "source": [
    "# Calculate the base recommendation, defined as the most frequently \n",
    "# sold item in each relevant category, top, bottom and accessory. This \n",
    "# approximation will be used when the user is new (i.e. no prior purchase)\n",
    "# or when no item satisfies the search, due to the preferences \n",
    "# (dress code, temperature)\n",
    "\n",
    "best_seller = old_cust.apply(sum,axis=0)\n",
    "best_seller_top = best_seller.loc[items.category == 'top']\n",
    "best_seller_top = best_match(best_seller_top, lst=best_seller_top.index)\n",
    "\n",
    "best_seller_bot = best_seller.loc[items.category == 'bottom']\n",
    "best_seller_bot = best_match(best_seller_bot, lst=best_seller_bot.index)\n",
    "\n",
    "best_seller_acc = best_seller.loc[items.category == 'accessory']\n",
    "best_seller_acc = best_match(best_seller_acc, lst=best_seller_acc.index)\n",
    "\n",
    "base_recommendation = [best_seller_top, best_seller_bot, best_seller_acc]\n",
    "\n",
    "print base_recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the limited size of the dataset, we can create a user profile by taking the internal product of the customer history and product features, normalized by the number of purchased items. For a general customer update, this is not necessary. As the prediction for user A is independent from user B we can build a function calculating the user profile for the single user.\n",
    "\n",
    "As the number of products and features increases, so does the time and space complexity. Not all features although are equally relevant. Depending on the relevant (time) window chosen for purchase history or the definition of meta-feautures, the item-features dataset can be partitioned before being used to update the user profile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************\n",
      "User profile\n",
      "************************\n",
      "          dress_code_biz casual  dress_code_biz formal  dress_code_black tie\n",
      "customer                                                                    \n",
      "cust_1                 0.200000               0.000000              0.000000\n",
      "cust_2                 0.250000               0.250000              0.250000\n",
      "cust_3                 0.333333               0.000000              0.333333\n",
      "cust_4                 0.000000               0.000000              0.333333\n",
      "cust_5                 0.000000               0.333333              0.000000\n",
      "cust_6                 0.000000               0.000000              0.000000\n",
      "cust_7                 0.200000               0.000000              0.200000\n",
      "cust_8                 0.000000               0.250000              0.250000\n",
      "cust_9                 0.000000               0.000000              0.500000\n",
      "cust_10                0.000000               0.000000              0.000000\n",
      "************************\n",
      "Outfit recommendations (no constraint)\n",
      "************************\n",
      "            Top   Bottom Accessory\n",
      "cust_1   item_7  item_28    item_5\n",
      "cust_2  item_24   item_9   item_19\n",
      "cust_3   item_8  item_39    item_2\n",
      "cust_4   item_1  item_35   item_29\n",
      "cust_5  item_16  item_23   item_32\n",
      "cust_6   item_7  item_22    item_6\n",
      "            Top   Bottom Accessory\n",
      "cust_52  item_7  item_20   item_38\n",
      "cust_55  item_7  item_20   item_38\n",
      "cust_79  item_7  item_20   item_38\n",
      "cust_89  item_7  item_20   item_38\n"
     ]
    }
   ],
   "source": [
    "# Calculate the user profile as internal product of encoded customers\n",
    "# and encoded items, normalized by the number of purchases per customer\n",
    "df_usr_profile = profile(old_cust)\n",
    "\n",
    "# For each relevant customer profile, calculate the cosine similarity\n",
    "# with the encoded items and pick the most similar item per relevant \n",
    "# category (top, bottom, accessory). Filter out already purchased items\n",
    "recommendations = recommender(df_usr_profile, old_cust, new_cust)\n",
    "\n",
    "# Notice that the last 4 rows are new customers, thereofore the base\n",
    "# recommendation was used to infer their preferences\n",
    "print '************************'\n",
    "print 'User profile'\n",
    "print '************************'\n",
    "print df_usr_profile.iloc[:10,:3]\n",
    "\n",
    "print '************************'\n",
    "print 'Outfit recommendations (no constraint)'\n",
    "print '************************'\n",
    "print recommendations.iloc[:6,] \n",
    "print recommendations.iloc[-4:,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4:\n",
    "Finally, we create an outfit recommendations for 10 customers using their inferred preferences and the following criteria:\n",
    "    * outfit 1:   biz formal, chilly\n",
    "    * outfit 2:   date night, warm\n",
    "    * outfit 3:   casual, hot\n",
    "Restricting the item list by using dress code and temperature dramatically reduces the number of available items. This has two effects, namely to make the cosine similarity less relevant (many customers share the same recommendation) and  to cause a category (top, bottom or accessory) to be left empty (no item for that combination). In this case the base recommendation is used. \n",
    "\n",
    "As the calculation is nearly identical to the previous one, I used the wrapper bonobos_recommender to hide the details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************\n",
      "base_recommendation\n",
      "************************\n",
      "['item_7', 'item_20', 'item_38']\n",
      "************************\n",
      "outfit_1\n",
      "************************\n",
      "             Top   Bottom Accessory\n",
      "cust_1   item_26  item_17   item_38\n",
      "cust_2   item_26  item_17   item_38\n",
      "cust_3   item_26  item_17   item_38\n",
      "cust_4   item_26  item_17   item_38\n",
      "cust_5   item_26  item_17   item_38\n",
      "cust_6   item_26  item_17   item_38\n",
      "cust_7   item_26  item_17   item_38\n",
      "cust_8   item_16  item_17   item_38\n",
      "cust_9   item_26  item_17   item_38\n",
      "cust_10  item_26  item_17   item_38\n",
      "************************\n",
      "outfit_2\n",
      "************************\n",
      "             Top   Bottom Accessory\n",
      "cust_1   item_34  item_35   item_38\n",
      "cust_2   item_34  item_35   item_38\n",
      "cust_3   item_34  item_36   item_38\n",
      "cust_4   item_34  item_35   item_38\n",
      "cust_5   item_34  item_36   item_38\n",
      "cust_6   item_34  item_36   item_38\n",
      "cust_7   item_34  item_36   item_38\n",
      "cust_8   item_34  item_35   item_38\n",
      "cust_9   item_34  item_36   item_38\n",
      "cust_10  item_34  item_36   item_38\n",
      "************************\n",
      "outfit_3\n",
      "************************\n",
      "            Top   Bottom Accessory\n",
      "cust_1   item_7  item_20   item_40\n",
      "cust_2   item_7  item_20   item_40\n",
      "cust_3   item_7  item_20   item_40\n",
      "cust_4   item_7  item_20   item_40\n",
      "cust_5   item_7  item_20   item_40\n",
      "cust_6   item_7  item_20   item_40\n",
      "cust_7   item_7  item_20   item_40\n",
      "cust_8   item_7  item_20   item_40\n",
      "cust_9   item_7  item_20   item_40\n",
      "cust_10  item_7  item_20   item_40\n"
     ]
    }
   ],
   "source": [
    "path = './bonobos_ds/custo_item.tsv'\n",
    "outfit_1 = bonobos_recommender(path, 'biz formal', 'chilly')\n",
    "outfit_2 = bonobos_recommender(path, 'date night', 'warm')\n",
    "outfit_3 = bonobos_recommender(path, 'casual', 'hot')\n",
    "print '************************'\n",
    "print 'base recommendation'\n",
    "print '************************'\n",
    "print base_recommendation\n",
    "\n",
    "print '************************'\n",
    "print 'outfit_1'\n",
    "print '************************'\n",
    "print outfit_1.iloc[:10,]\n",
    "\n",
    "print '************************'\n",
    "print 'outfit_2'\n",
    "print '************************'\n",
    "print outfit_2.iloc[:10,]\n",
    "\n",
    "print '************************'\n",
    "print 'outfit_3'\n",
    "print '************************'\n",
    "print outfit_3.iloc[:10,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
